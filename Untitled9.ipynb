{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO61+RRlmkYct57lKLlXeTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harigopi1825/hari18/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cj5YzVnzzWg",
        "outputId": "bfe8ecd9-29e3-4163-8091-c11e11eb92d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hari18'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 60 (delta 0), reused 3 (delta 0), pack-reused 57 (from 1)\u001b[K\n",
            "Receiving objects: 100% (60/60), 136.08 MiB | 25.46 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (44/44), done.\n",
            "Encountered 1 file(s) that should have been pointers, but weren't:\n",
            "\tTraffic-Density-Analyzer-main/Yolo-Weights/yolov8l.pt\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Harigopi1825/hari18.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hari18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul8H8srcz1VA",
        "outputId": "7c96c27c-ac94-4ee1-df1b-524e8a4d2105"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hari18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p images videos\n"
      ],
      "metadata": {
        "id": "H14EwMdmz3S1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls images\n",
        "!ls videos\n"
      ],
      "metadata": {
        "id": "RJGk9aVY0HSP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision opencv-python ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILq1mZzn0LDO",
        "outputId": "3ec969a1-963c-40f2-85b0-1c5410277a1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.24-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Downloading ultralytics-8.3.24-py3-none-any.whl (877 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.7/877.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.24 ultralytics-thop-2.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = \"\"\"\n",
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Ensure the necessary directories exist\n",
        "directories = ['images', 'videos', 'results']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Check if the model file exists\n",
        "model_path = 'Yolo-Weights/yolov8l.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Model file {model_path} not found.\")\n",
        "else:\n",
        "    print(f\"Model file found at {model_path}\")\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}. Ensure the model file is correct and try again.\")\n",
        "    model = None\n",
        "\n",
        "# Define directories\n",
        "image_folder = 'images/'\n",
        "video_folder = 'videos/'\n",
        "result_folder = 'results/'\n",
        "\n",
        "# Process Images\n",
        "if model and os.listdir(image_folder):\n",
        "    images = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "    for image_path in images:\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model(image)\n",
        "        vehicle_count = len(results.xyxy[0])\n",
        "        print(f'Vehicles detected in {os.path.basename(image_path)}: {vehicle_count}')\n",
        "        # Save processed image\n",
        "        cv2.imwrite(os.path.join(result_folder, 'processed_' + os.path.basename(image_path)), image)\n",
        "else:\n",
        "    print(f\"No image files found in the directory: {image_folder}. Please upload .jpg images.\")\n",
        "\n",
        "# Process Videos\n",
        "if model and os.listdir(video_folder):\n",
        "    videos = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "    for video_path in videos:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model(frame)\n",
        "            # Process and save each frame (example, processing can vary)\n",
        "            vehicle_count = len(results.xyxy[0])\n",
        "            print(f'Frame processed from {os.path.basename(video_path)}: {vehicle_count}')\n",
        "            cv2.imwrite(os.path.join(result_folder, 'frame_' + os.path.basename(video_path)), frame)\n",
        "        cap.release()\n",
        "else:\n",
        "    print(f\"No video files found in the directory: {video_folder}. Please upload .mp4 videos.\")\n",
        "\n",
        "print(\"Traffic Density Analysis Completed!\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a file\n",
        "with open('traffic_density_analysis.py', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Script saved as traffic_density_analysis.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd964lLY0NWi",
        "outputId": "449eb96f-c06f-407b-b90c-d19546f1a1aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script saved as traffic_density_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python traffic_density_analysis.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX8jhxkV0Qcu",
        "outputId": "0f8149e8-54dd-463a-fca1-979ba630ac08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Model file Yolo-Weights/yolov8l.pt not found.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'Yolo-Weights/yolov8l.pt'...\n",
            "100% 83.7M/83.7M [00:00<00:00, 220MB/s]\n",
            "No image files found in the directory: images/. Please upload .jpg images.\n",
            "No video files found in the directory: videos/. Please upload .mp4 videos.\n",
            "Traffic Density Analysis Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Harigopi1825/hari18.git\n",
        "%cd hari18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArqQBDo00TSw",
        "outputId": "844fa037-d771-46cd-c168-442675d4a733"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hari18'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 60 (delta 0), reused 3 (delta 0), pack-reused 57 (from 1)\u001b[K\n",
            "Receiving objects: 100% (60/60), 136.08 MiB | 35.40 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (44/44), done.\n",
            "Encountered 1 file(s) that should have been pointers, but weren't:\n",
            "\tTraffic-Density-Analyzer-main/Yolo-Weights/yolov8l.pt\n",
            "/content/hari18/hari18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories\n",
        "!mkdir -p images videos\n",
        "\n",
        "# List contents of directories\n",
        "!ls images\n",
        "!ls videos\n"
      ],
      "metadata": {
        "id": "CdAtosE10pe0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List contents again to ensure files are uploaded\n",
        "!ls images\n",
        "!ls videos\n"
      ],
      "metadata": {
        "id": "bPTdf6id0r7s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python traffic_density_analysis.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKmvHdPH0t8F",
        "outputId": "f1a3bc7b-323e-4801-e344-c323c5625847"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/hari18/hari18/traffic_density_analysis.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/hari18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUtW8VmE0vn9",
        "outputId": "81b087ea-255d-4350-fabc-b5bf057b7857"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hari18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = \"\"\"\n",
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Ensure the necessary directories exist\n",
        "directories = ['images', 'videos', 'results']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Check if the model file exists\n",
        "model_path = 'Yolo-Weights/yolov8l.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Model file {model_path} not found.\")\n",
        "else:\n",
        "    print(f\"Model file found at {model_path}\")\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}. Ensure the model file is correct and try again.\")\n",
        "    model = None\n",
        "\n",
        "# Define directories\n",
        "image_folder = 'images/'\n",
        "video_folder = 'videos/'\n",
        "result_folder = 'results/'\n",
        "\n",
        "# Process Images\n",
        "if model and os.listdir(image_folder):\n",
        "    images = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "    for image_path in images:\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model(image)\n",
        "        vehicle_count = len(results.xyxy[0])\n",
        "        print(f'Vehicles detected in {os.path.basename(image_path)}: {vehicle_count}')\n",
        "        # Save processed image\n",
        "        cv2.imwrite(os.path.join(result_folder, 'processed_' + os.path.basename(image_path)), image)\n",
        "else:\n",
        "    print(f\"No image files found in the directory: {image_folder}. Please upload .jpg images.\")\n",
        "\n",
        "# Process Videos\n",
        "if model and os.listdir(video_folder):\n",
        "    videos = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "    for video_path in videos:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model(frame)\n",
        "            # Process and save each frame (example, processing can vary)\n",
        "            vehicle_count = len(results.xyxy[0])\n",
        "            print(f'Frame processed from {os.path.basename(video_path)}: {vehicle_count}')\n",
        "            cv2.imwrite(os.path.join(result_folder, 'frame_' + os.path.basename(video_path)), frame)\n",
        "        cap.release()\n",
        "else:\n",
        "    print(f\"No video files found in the directory: {video_folder}. Please upload .mp4 videos.\")\n",
        "\n",
        "print(\"Traffic Density Analysis Completed!\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a file\n",
        "with open('traffic_density_analysis.py', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Script saved as traffic_density_analysis.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax40uauW1BPj",
        "outputId": "7e47952d-0152-4214-9557-53c93bea516c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script saved as traffic_density_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWOEjHDw1JKQ",
        "outputId": "12afd2ee-60c7-4d5f-b47d-81f66075acfa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hari18\tresults\t\t\t     Traffic-Density-Analyzer-main  Yolo-Weights\n",
            "images\ttraffic_density_analysis.py  videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python traffic_density_analysis.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozVNbUqq1MYu",
        "outputId": "6086f244-f11a-4d2f-fa26-79f808c6d5d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file found at Yolo-Weights/yolov8l.pt\n",
            "No image files found in the directory: images/. Please upload .jpg images.\n",
            "No video files found in the directory: videos/. Please upload .mp4 videos.\n",
            "Traffic Density Analysis Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/hari18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEhDXeUM1QpP",
        "outputId": "ae4cb43b-9a77-4091-b96a-9c4190bcd088"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hari18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!ls images\n",
        "!ls videos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I47Yq4Zp2JjQ",
        "outputId": "a75d1c28-d3d4-41ee-d153-ab1436a346db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hari18\tresults\t\t\t     Traffic-Density-Analyzer-main  Yolo-Weights\n",
            "images\ttraffic_density_analysis.py  videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p images videos results\n"
      ],
      "metadata": {
        "id": "i0o9i6MY2LOu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code = \"\"\"\n",
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Ensure the necessary directories exist\n",
        "directories = ['images', 'videos', 'results']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Check if the model file exists\n",
        "model_path = 'Yolo-Weights/yolov8l.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Model file {model_path} not found.\")\n",
        "else:\n",
        "    print(f\"Model file found at {model_path}\")\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}. Ensure the model file is correct and try again.\")\n",
        "    model = None\n",
        "\n",
        "# Define directories\n",
        "image_folder = 'images/'\n",
        "video_folder = 'videos/'\n",
        "result_folder = 'results/'\n",
        "\n",
        "# Process Images\n",
        "if model and os.listdir(image_folder):\n",
        "    images = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "    for image_path in images:\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model(image)\n",
        "        vehicle_count = len(results.xyxy[0])\n",
        "        print(f'Vehicles detected in {os.path.basename(image_path)}: {vehicle_count}')\n",
        "        # Save processed image\n",
        "        cv2.imwrite(os.path.join(result_folder, 'processed_' + os.path.basename(image_path)), image)\n",
        "else:\n",
        "    print(f\"No image files found in the directory: {image_folder}. Please upload .jpg images.\")\n",
        "\n",
        "# Process Videos\n",
        "if model and os.listdir(video_folder):\n",
        "    videos = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "    for video_path in videos:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model(frame)\n",
        "            # Process and save each frame (example, processing can vary)\n",
        "            vehicle_count = len(results.xyxy[0])\n",
        "            print(f'Frame processed from {os.path.basename(video_path)}: {vehicle_count}')\n",
        "            cv2.imwrite(os.path.join(result_folder, 'frame_' + os.path.basename(video_path)), frame)\n",
        "        cap.release()\n",
        "else:\n",
        "    print(f\"No video files found in the directory: {video_folder}. Please upload .mp4 videos.\")\n",
        "\n",
        "print(\"Traffic Density Analysis Completed!\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a file\n",
        "with open('traffic_density_analysis.py', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"Script saved as traffic_density_analysis.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0D_4Far2Nyw",
        "outputId": "4816b34c-c232-4b89-8757-771e1485f343"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script saved as traffic_density_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWhBV6vn2Qzr",
        "outputId": "eb06f696-daac-4727-e6dc-3db8c4f740cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hari18\tresults\t\t\t     Traffic-Density-Analyzer-main  Yolo-Weights\n",
            "images\ttraffic_density_analysis.py  videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python traffic_density_analysis.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSP7f_Z42UTy",
        "outputId": "01168ca1-b9db-446a-eb39-fdbf9274e582"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file found at Yolo-Weights/yolov8l.pt\n",
            "No image files found in the directory: images/. Please upload .jpg images.\n",
            "No video files found in the directory: videos/. Please upload .mp4 videos.\n",
            "Traffic Density Analysis Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/hari18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHu9LJ4-2XSU",
        "outputId": "34101519-8c17-4c88-c209-9ceb3c2ce4b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hari18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21wS1wXT3IBD",
        "outputId": "6dc525f3-f704-4bd0-dc79-37ea94e4b4ee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hari18\tresults\t\t\t     Traffic-Density-Analyzer-main  Yolo-Weights\n",
            "images\ttraffic_density_analysis.py  videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p images videos\n"
      ],
      "metadata": {
        "id": "Rqf9uksj3KPv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls images\n",
        "!ls videos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWKBdUJ83Mkz",
        "outputId": "598563b8-0999-4224-826b-dd4b2c6ebc56"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bike.jpg  car1.png  green.jpg\t      katolNaka1.jpg  red.jpg\t    yellow.jpg\n",
            "bus.jpg   car2.jpg  intersection.jpg  katolNaka.jpg   rickshaw.jpg\n",
            "car1.jpg  car.jpg   intersection.png  mod_int.jpg     truck.jpg\n",
            "video1.mp4  video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure directories exist\n",
        "!mkdir -p images videos\n",
        "\n",
        "# List the contents to ensure files are uploaded correctly\n",
        "print(\"Contents of 'images' directory:\")\n",
        "!ls images\n",
        "\n",
        "print(\"Contents of 'videos' directory:\")\n",
        "!ls videos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoB5BxIT37Av",
        "outputId": "a1de1134-1be2-4c7e-d27c-a54fc55ef1f4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'images' directory:\n",
            "bike.jpg  car1.png  green.jpg\t      katolNaka1.jpg  red.jpg\t    yellow.jpg\n",
            "bus.jpg   car2.jpg  intersection.jpg  katolNaka.jpg   rickshaw.jpg\n",
            "car1.jpg  car.jpg   intersection.png  mod_int.jpg     truck.jpg\n",
            "Contents of 'videos' directory:\n",
            "video1.mp4  video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/hari18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq0THqqd3_FR",
        "outputId": "b1595efe-d452-4ec3-91d5-c8b54113f5f5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hari18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python traffic_density_analysis.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcIohkst4Bti",
        "outputId": "6026eccc-3f67-4d3f-d6ee-5dc08bf0c3ee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file found at Yolo-Weights/yolov8l.pt\n",
            "\n",
            "0: 640x288 1 refrigerator, 1531.6ms\n",
            "Speed: 20.5ms preprocess, 1531.6ms inference, 35.7ms postprocess per image at shape (1, 3, 640, 288)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/hari18/traffic_density_analysis.py\", line 37, in <module>\n",
            "    vehicle_count = len(results.xyxy[0])\n",
            "AttributeError: 'list' object has no attribute 'xyxy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Ensure the necessary directories exist\n",
        "directories = ['images', 'videos', 'results']\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Check if the model file exists\n",
        "model_path = 'Yolo-Weights/yolov8l.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Model file {model_path} not found.\")\n",
        "else:\n",
        "    print(f\"Model file found at {model_path}\")\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}. Ensure the model file is correct and try again.\")\n",
        "    model = None\n",
        "\n",
        "# Define directories\n",
        "image_folder = 'images/'\n",
        "video_folder = 'videos/'\n",
        "result_folder = 'results/'\n",
        "\n",
        "# Process Images\n",
        "if model and os.listdir(image_folder):\n",
        "    images = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "    for image_path in images:\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model(image)[0]  # Access the first element of the list\n",
        "        vehicle_count = len(results)  # The length of results should give the number of detected objects\n",
        "        print(f'Vehicles detected in {os.path.basename(image_path)}: {vehicle_count}')\n",
        "        # Save processed image\n",
        "        processed_image_path = os.path.join(result_folder, 'processed_' + os.path.basename(image_path))\n",
        "        cv2.imwrite(processed_image_path, image)\n",
        "else:\n",
        "    print(f\"No image files found in the directory: {image_folder}. Please upload .jpg images.\")\n",
        "\n",
        "# Process Videos\n",
        "if model and os.listdir(video_folder):\n",
        "    videos = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "    for video_path in videos:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model(frame)[0]  # Access the first element of the list\n",
        "            vehicle_count = len(results)  # The length of results should give the number of detected objects\n",
        "            print(f'Frame processed from {os.path.basename(video_path)}: {vehicle_count}')\n",
        "            processed_frame_path = os.path.join(result_folder, f'frame_{os.path.basename(video_path).split(\".\")[0]}_{frame_count}.jpg')\n",
        "            cv2.imwrite(processed_frame_path, frame)\n",
        "            frame_count += 1\n",
        "        cap.release()\n",
        "else:\n",
        "    print(f\"No video files found in the directory: {video_folder}. Please upload .mp4 videos.\")\n",
        "\n",
        "print(\"Traffic Density Analysis Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siyIAADd5Bnn",
        "outputId": "e5e4fa83-3b72-47d9-9d49-a0b88772b0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model file found at Yolo-Weights/yolov8l.pt\n",
            "\n",
            "0: 640x288 1 refrigerator, 1945.2ms\n",
            "Speed: 3.4ms preprocess, 1945.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "Vehicles detected in truck.jpg: 1\n",
            "\n",
            "0: 640x256 1 traffic light, 1143.1ms\n",
            "Speed: 2.0ms preprocess, 1143.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "Vehicles detected in red.jpg: 1\n",
            "\n",
            "0: 640x256 (no detections), 1158.7ms\n",
            "Speed: 1.9ms preprocess, 1158.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "Vehicles detected in green.jpg: 0\n",
            "\n",
            "0: 288x640 (no detections), 1210.8ms\n",
            "Speed: 3.7ms preprocess, 1210.8ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Vehicles detected in car1.jpg: 0\n",
            "\n",
            "0: 448x640 (no detections), 1889.1ms\n",
            "Speed: 4.3ms preprocess, 1889.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Vehicles detected in mod_int.jpg: 0\n",
            "\n",
            "0: 448x640 (no detections), 1890.4ms\n",
            "Speed: 5.0ms preprocess, 1890.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Vehicles detected in katolNaka.jpg: 0\n",
            "\n",
            "0: 640x288 1 fire hydrant, 1 parking meter, 1257.8ms\n",
            "Speed: 2.5ms preprocess, 1257.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "Vehicles detected in bike.jpg: 2\n",
            "\n",
            "0: 640x256 1 traffic light, 1177.3ms\n",
            "Speed: 1.8ms preprocess, 1177.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "Vehicles detected in yellow.jpg: 1\n",
            "\n",
            "0: 384x640 (no detections), 2610.3ms\n",
            "Speed: 3.9ms preprocess, 2610.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Vehicles detected in intersection.jpg: 0\n",
            "\n",
            "0: 640x288 (no detections), 1265.4ms\n",
            "Speed: 2.7ms preprocess, 1265.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 288)\n",
            "Vehicles detected in car.jpg: 0\n",
            "\n",
            "0: 448x640 (no detections), 1884.4ms\n",
            "Speed: 4.4ms preprocess, 1884.4ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Vehicles detected in katolNaka1.jpg: 0\n",
            "\n",
            "0: 224x640 (no detections), 966.6ms\n",
            "Speed: 1.8ms preprocess, 966.6ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
            "Vehicles detected in car2.jpg: 0\n",
            "\n",
            "0: 640x224 1 refrigerator, 1025.8ms\n",
            "Speed: 1.8ms preprocess, 1025.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "Vehicles detected in bus.jpg: 1\n",
            "\n",
            "0: 640x448 (no detections), 1934.7ms\n",
            "Speed: 2.8ms preprocess, 1934.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Vehicles detected in rickshaw.jpg: 0\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 3 motorcycles, 1 traffic light, 1656.4ms\n",
            "Speed: 6.7ms preprocess, 1656.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 3 motorcycles, 1 traffic light, 1957.2ms\n",
            "Speed: 4.0ms preprocess, 1957.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 4 motorcycles, 1 traffic light, 2308.8ms\n",
            "Speed: 7.3ms preprocess, 2308.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 1 traffic light, 1627.7ms\n",
            "Speed: 5.6ms preprocess, 1627.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 3 motorcycles, 1630.8ms\n",
            "Speed: 3.8ms preprocess, 1630.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 3 motorcycles, 1653.0ms\n",
            "Speed: 6.7ms preprocess, 1653.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 3 motorcycles, 1 truck, 1624.5ms\n",
            "Speed: 3.8ms preprocess, 1624.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 4 motorcycles, 1 truck, 1644.5ms\n",
            "Speed: 4.1ms preprocess, 1644.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 3 motorcycles, 1 truck, 1990.6ms\n",
            "Speed: 4.7ms preprocess, 1990.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 3 motorcycles, 1 truck, 2301.0ms\n",
            "Speed: 8.3ms preprocess, 2301.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 3 motorcycles, 1 truck, 1 traffic light, 1618.1ms\n",
            "Speed: 3.7ms preprocess, 1618.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 3 motorcycles, 1 truck, 1 traffic light, 1658.5ms\n",
            "Speed: 3.9ms preprocess, 1658.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 3 motorcycles, 2 trucks, 1 traffic light, 1666.8ms\n",
            "Speed: 5.8ms preprocess, 1666.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 3 motorcycles, 3 trucks, 1 traffic light, 1633.7ms\n",
            "Speed: 3.9ms preprocess, 1633.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 15\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 3 motorcycles, 3 trucks, 1 traffic light, 1643.1ms\n",
            "Speed: 5.6ms preprocess, 1643.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 4 motorcycles, 2 trucks, 1 traffic light, 2008.2ms\n",
            "Speed: 3.9ms preprocess, 2008.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 3 motorcycles, 1 truck, 1 traffic light, 2283.5ms\n",
            "Speed: 7.2ms preprocess, 2283.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 3 motorcycles, 2 trucks, 1 traffic light, 1641.4ms\n",
            "Speed: 7.6ms preprocess, 1641.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 3 motorcycles, 3 trucks, 1 traffic light, 2042.8ms\n",
            "Speed: 6.2ms preprocess, 2042.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 16\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 2 motorcycles, 3 trucks, 1 traffic light, 2283.0ms\n",
            "Speed: 4.8ms preprocess, 2283.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 2 motorcycles, 2 trucks, 1 traffic light, 1665.8ms\n",
            "Speed: 5.6ms preprocess, 1665.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 2 motorcycles, 2 trucks, 1 traffic light, 1677.7ms\n",
            "Speed: 5.8ms preprocess, 1677.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 2 motorcycles, 5 trucks, 2600.6ms\n",
            "Speed: 4.3ms preprocess, 2600.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 3 motorcycles, 2 trucks, 1 traffic light, 1654.4ms\n",
            "Speed: 7.1ms preprocess, 1654.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 3 motorcycles, 2 trucks, 1 traffic light, 1645.2ms\n",
            "Speed: 4.9ms preprocess, 1645.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 16\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 3 motorcycles, 1 truck, 1 traffic light, 1642.9ms\n",
            "Speed: 5.5ms preprocess, 1642.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 3 motorcycles, 1 truck, 1 traffic light, 1638.4ms\n",
            "Speed: 6.4ms preprocess, 1638.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 3 motorcycles, 1 truck, 1 traffic light, 1658.6ms\n",
            "Speed: 4.3ms preprocess, 1658.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 3 motorcycles, 5 trucks, 1 traffic light, 1749.3ms\n",
            "Speed: 6.5ms preprocess, 1749.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 15\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 4 motorcycles, 3 trucks, 1 traffic light, 2518.4ms\n",
            "Speed: 11.2ms preprocess, 2518.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 15\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 motorcycles, 3 trucks, 1 traffic light, 1648.2ms\n",
            "Speed: 8.3ms preprocess, 1648.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 3 motorcycles, 1 truck, 2 traffic lights, 1639.7ms\n",
            "Speed: 5.5ms preprocess, 1639.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 3 motorcycles, 1 truck, 1 traffic light, 1641.6ms\n",
            "Speed: 3.9ms preprocess, 1641.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 5 motorcycles, 1 traffic light, 1649.8ms\n",
            "Speed: 5.6ms preprocess, 1649.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 4 motorcycles, 1 truck, 1641.9ms\n",
            "Speed: 3.8ms preprocess, 1641.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 4 motorcycles, 1 truck, 1818.1ms\n",
            "Speed: 4.2ms preprocess, 1818.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 4 motorcycles, 2441.0ms\n",
            "Speed: 9.1ms preprocess, 2441.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 3 persons, 5 cars, 3 motorcycles, 1632.0ms\n",
            "Speed: 5.3ms preprocess, 1632.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 4 motorcycles, 1 traffic light, 1672.0ms\n",
            "Speed: 8.3ms preprocess, 1672.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 1 truck, 1672.0ms\n",
            "Speed: 5.4ms preprocess, 1672.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 2 trucks, 1 traffic light, 1626.5ms\n",
            "Speed: 4.5ms preprocess, 1626.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 2 persons, 1 motorcycle, 1 bus, 4 trucks, 1 traffic light, 1609.7ms\n",
            "Speed: 3.8ms preprocess, 1609.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 1883.3ms\n",
            "Speed: 3.9ms preprocess, 1883.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 2356.6ms\n",
            "Speed: 4.3ms preprocess, 2356.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 1660.9ms\n",
            "Speed: 6.9ms preprocess, 1660.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 1 bus, 2 trucks, 1634.7ms\n",
            "Speed: 6.5ms preprocess, 1634.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 truck, 1636.0ms\n",
            "Speed: 5.6ms preprocess, 1636.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 2 trucks, 1652.2ms\n",
            "Speed: 3.8ms preprocess, 1652.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 2 trucks, 1 traffic light, 1635.2ms\n",
            "Speed: 3.8ms preprocess, 1635.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 motorcycle, 3 trucks, 1940.5ms\n",
            "Speed: 5.4ms preprocess, 1940.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 3 trucks, 2308.7ms\n",
            "Speed: 4.6ms preprocess, 2308.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 1660.7ms\n",
            "Speed: 3.9ms preprocess, 1660.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 1640.8ms\n",
            "Speed: 3.9ms preprocess, 1640.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 motorcycle, 3 trucks, 1 traffic light, 1615.0ms\n",
            "Speed: 7.4ms preprocess, 1615.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 motorcycle, 2 trucks, 1 traffic light, 1635.3ms\n",
            "Speed: 3.9ms preprocess, 1635.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 2 motorcycles, 2 trucks, 1 traffic light, 1639.7ms\n",
            "Speed: 3.8ms preprocess, 1639.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 2 motorcycles, 2 trucks, 1914.5ms\n",
            "Speed: 5.5ms preprocess, 1914.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 2 motorcycles, 2 trucks, 1 traffic light, 2336.7ms\n",
            "Speed: 4.1ms preprocess, 2336.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 motorcycle, 3 trucks, 1 traffic light, 1599.7ms\n",
            "Speed: 4.5ms preprocess, 1599.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 2 motorcycles, 3 trucks, 1 traffic light, 1642.9ms\n",
            "Speed: 3.8ms preprocess, 1642.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 motorcycle, 1 traffic light, 1649.9ms\n",
            "Speed: 4.4ms preprocess, 1649.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 1657.8ms\n",
            "Speed: 5.3ms preprocess, 1657.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 1671.7ms\n",
            "Speed: 5.4ms preprocess, 1671.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 3 motorcycles, 1 bus, 3 trucks, 1 traffic light, 1967.4ms\n",
            "Speed: 5.6ms preprocess, 1967.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 15\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 3 motorcycles, 1 bus, 1 traffic light, 2301.8ms\n",
            "Speed: 8.4ms preprocess, 2301.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 4 motorcycles, 1 truck, 1 traffic light, 1667.1ms\n",
            "Speed: 5.6ms preprocess, 1667.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 2 motorcycles, 1 truck, 1 traffic light, 1644.7ms\n",
            "Speed: 4.8ms preprocess, 1644.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 5 motorcycles, 1 truck, 1659.2ms\n",
            "Speed: 3.8ms preprocess, 1659.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 6 motorcycles, 1632.3ms\n",
            "Speed: 4.1ms preprocess, 1632.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 4 motorcycles, 1 bus, 1 traffic light, 1648.6ms\n",
            "Speed: 5.8ms preprocess, 1648.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 4 motorcycles, 1 traffic light, 2035.5ms\n",
            "Speed: 6.8ms preprocess, 2035.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 5 motorcycles, 1 bus, 1 traffic light, 2259.1ms\n",
            "Speed: 5.4ms preprocess, 2259.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 2 motorcycles, 1 bus, 1 truck, 1684.1ms\n",
            "Speed: 5.7ms preprocess, 1684.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 motorcycles, 2 buss, 1 traffic light, 1658.1ms\n",
            "Speed: 5.8ms preprocess, 1658.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 3 motorcycles, 1 bus, 1627.0ms\n",
            "Speed: 4.0ms preprocess, 1627.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 2 motorcycles, 1640.4ms\n",
            "Speed: 3.7ms preprocess, 1640.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 motorcycle, 1 bus, 1 truck, 1630.2ms\n",
            "Speed: 3.8ms preprocess, 1630.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 14\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 bus, 2 trucks, 1 traffic light, 2144.9ms\n",
            "Speed: 4.1ms preprocess, 2144.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 2165.7ms\n",
            "Speed: 4.1ms preprocess, 2165.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 1625.5ms\n",
            "Speed: 5.3ms preprocess, 1625.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1633.7ms\n",
            "Speed: 3.7ms preprocess, 1633.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 motorcycle, 2 trucks, 1638.3ms\n",
            "Speed: 3.8ms preprocess, 1638.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 5 cars, 1 motorcycle, 4 trucks, 1601.3ms\n",
            "Speed: 4.5ms preprocess, 1601.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 2 trucks, 1651.7ms\n",
            "Speed: 3.7ms preprocess, 1651.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 6\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 6 trucks, 2090.9ms\n",
            "Speed: 3.6ms preprocess, 2090.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 6 trucks, 2168.6ms\n",
            "Speed: 8.8ms preprocess, 2168.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 cars, 1 train, 5 trucks, 1634.5ms\n",
            "Speed: 5.6ms preprocess, 1634.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 6 trucks, 1638.0ms\n",
            "Speed: 3.9ms preprocess, 1638.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 3 cars, 5 trucks, 1642.5ms\n",
            "Speed: 3.9ms preprocess, 1642.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 5 cars, 1 motorcycle, 5 trucks, 1 traffic light, 1628.9ms\n",
            "Speed: 3.7ms preprocess, 1628.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 2 cars, 6 trucks, 1 traffic light, 1626.1ms\n",
            "Speed: 6.9ms preprocess, 1626.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 2 cars, 5 trucks, 2251.3ms\n",
            "Speed: 3.7ms preprocess, 2251.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 1 car, 6 trucks, 2895.8ms\n",
            "Speed: 4.0ms preprocess, 2895.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 3 cars, 6 trucks, 1920.3ms\n",
            "Speed: 6.0ms preprocess, 1920.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 6 trucks, 1660.4ms\n",
            "Speed: 9.0ms preprocess, 1660.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 6 trucks, 1620.7ms\n",
            "Speed: 4.6ms preprocess, 1620.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 6\n",
            "\n",
            "0: 384x640 7 trucks, 1651.1ms\n",
            "Speed: 5.2ms preprocess, 1651.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 5 trucks, 1613.8ms\n",
            "Speed: 4.3ms preprocess, 1613.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 cars, 5 trucks, 1638.3ms\n",
            "Speed: 3.7ms preprocess, 1638.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 1 bus, 5 trucks, 2468.3ms\n",
            "Speed: 3.7ms preprocess, 2468.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 6\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 5 trucks, 1788.4ms\n",
            "Speed: 4.1ms preprocess, 1788.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 4 trucks, 1 traffic light, 1636.8ms\n",
            "Speed: 4.2ms preprocess, 1636.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 2 trucks, 1627.1ms\n",
            "Speed: 3.6ms preprocess, 1627.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 3 cars, 5 trucks, 1647.3ms\n",
            "Speed: 3.8ms preprocess, 1647.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 2 cars, 5 trucks, 1 traffic light, 1629.6ms\n",
            "Speed: 4.2ms preprocess, 1629.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 3 cars, 4 trucks, 1 traffic light, 1670.0ms\n",
            "Speed: 3.9ms preprocess, 1670.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 4 trucks, 1 traffic light, 2474.8ms\n",
            "Speed: 4.5ms preprocess, 2474.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 4 cars, 3 trucks, 1 traffic light, 1835.9ms\n",
            "Speed: 4.2ms preprocess, 1835.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 4 cars, 4 trucks, 1 traffic light, 1638.2ms\n",
            "Speed: 3.2ms preprocess, 1638.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 1 traffic light, 1660.6ms\n",
            "Speed: 4.5ms preprocess, 1660.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 3 cars, 3 trucks, 1 traffic light, 1635.6ms\n",
            "Speed: 5.0ms preprocess, 1635.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 7\n",
            "\n",
            "0: 384x640 3 cars, 5 trucks, 1 traffic light, 1643.7ms\n",
            "Speed: 3.8ms preprocess, 1643.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 5 cars, 4 trucks, 1 traffic light, 1622.5ms\n",
            "Speed: 5.6ms preprocess, 1622.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 5 cars, 1 motorcycle, 4 trucks, 1 traffic light, 2460.5ms\n",
            "Speed: 4.5ms preprocess, 2460.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 8 cars, 3 trucks, 1 traffic light, 1797.2ms\n",
            "Speed: 6.7ms preprocess, 1797.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 6 cars, 3 trucks, 1 traffic light, 1602.6ms\n",
            "Speed: 4.1ms preprocess, 1602.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 1 traffic light, 1658.1ms\n",
            "Speed: 3.9ms preprocess, 1658.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 9\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 6 trucks, 1 traffic light, 1627.7ms\n",
            "Speed: 3.9ms preprocess, 1627.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 motorcycle, 1 truck, 2 traffic lights, 1619.3ms\n",
            "Speed: 5.5ms preprocess, 1619.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 1 traffic light, 1644.6ms\n",
            "Speed: 3.8ms preprocess, 1644.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 8\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 trucks, 1 traffic light, 2448.7ms\n",
            "Speed: 5.0ms preprocess, 2448.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 motorcycles, 2 trucks, 1 traffic light, 1826.5ms\n",
            "Speed: 4.7ms preprocess, 1826.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 2 motorcycles, 3 trucks, 2 traffic lights, 1626.2ms\n",
            "Speed: 5.5ms preprocess, 1626.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 15\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 trucks, 1 traffic light, 1635.0ms\n",
            "Speed: 3.9ms preprocess, 1635.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 3 trucks, 1 traffic light, 1624.6ms\n",
            "Speed: 6.0ms preprocess, 1624.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 motorcycle, 2 trucks, 1 traffic light, 1624.1ms\n",
            "Speed: 4.2ms preprocess, 1624.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 15\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 motorcycle, 3 trucks, 1656.5ms\n",
            "Speed: 4.2ms preprocess, 1656.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 motorcycle, 2 trucks, 1 traffic light, 2444.7ms\n",
            "Speed: 4.5ms preprocess, 2444.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 motorcycle, 2 trucks, 1837.3ms\n",
            "Speed: 4.6ms preprocess, 1837.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 motorcycles, 1 truck, 1 traffic light, 1659.2ms\n",
            "Speed: 2.8ms preprocess, 1659.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 3 motorcycles, 2 trucks, 1 traffic light, 1659.0ms\n",
            "Speed: 4.4ms preprocess, 1659.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 13\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 motorcycle, 1 truck, 1 traffic light, 1635.9ms\n",
            "Speed: 4.1ms preprocess, 1635.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 10\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 2 motorcycles, 1 truck, 1 traffic light, 1645.2ms\n",
            "Speed: 5.7ms preprocess, 1645.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 2 motorcycles, 1 truck, 1 traffic light, 1620.7ms\n",
            "Speed: 3.1ms preprocess, 1620.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 2 motorcycles, 1 truck, 1 traffic light, 2514.8ms\n",
            "Speed: 4.1ms preprocess, 2514.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 12\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 2 motorcycles, 1 truck, 1789.7ms\n",
            "Speed: 4.0ms preprocess, 1789.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame processed from video1.mp4: 11\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qx6tMgfg6svq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}